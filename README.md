# Python-Backend-Worker-Template

This is a template python repo that contains the skeleton to create new backend worker at Wish.
It is a light-weighted wrapper based off celery worker and flask in WSGI server. It utilizes celery + SQS as broker, provides convenience in both producer and consumer ends

It contains the following:

BE worker skeleton code
Tests
Metrics
Dockerfiles
Gitlab CI files for automating the building and registering of new container images
Tracing

# Caveats
- Although celery worker supports other brokers e.g. RMQ, Redis and Zookeeper, for the sake of saving the work to setup the broker, we decided to use SQS as broker at this moment. There are some caveats in using celery with SQS, so some of the celery features/configurations are not available, e.g. remote control, celery native monitoring etc. 
For more details, please refer to https://docs.celeryproject.org/en/stable/getting-started/brokers/index.html#broker-overview

- Currently, we only support celery worker from [prefork](https://docs.celeryproject.org/en/stable/internals/reference/celery.concurrency.prefork.html). Individual worker is an independant process from the executaion pool. We `DO NOT` support any other coroutine mode, like `gevent` or `eventlet` at this moment.


# Setting up a new worker

## Pre-step

We recommend to use Python version >= 3.7 to develop the worker. It does not support any Python 2.x, and may be broken in some Python < 3.7 versions (we didn't test)

## 1. Create a Project off the Templateï¼ˆskip this if your repo is created by one-click)

You can setup a new worker repo on the template page [here](https://github.com/ContextLogic/python-backend-worker-template/generate).

Note: The name of the Repository should be the name of the Worker.

Fill in the Repository name, and the Description. Double check the repository is set to Private.

## 2. Migrate Project to Gitlab

Once the project is in Github, send a message to the #Gitlab slack channel with the link of your new repository asking for your repository to be linked to Gitlab.

## 3. Testing Your Worker Locally (PLEASE CONNECT TO VPN)

### pre-steps

#### Setup AWS CREDENTIALS
please make sure that you've setup your AWS credentials at `~/.aws/credentials` and setup the env vars of

```bash
AWS_SECRET_ACCESS_KEY=xxxx...
AWS_ACCESS_KEY_ID=xxxx...
```

### I. run from source code

#### Setup Prometheus Multi-Process Mode
```bash
export prometheus_multiproc_dir=./prometheus_multiproc_dir
```
this sets the temoprary directory to store the metrics data generated by each worker process.

#### Install Poetry
```bash
pip3 install poetry
```

#### install deps
```bash
poetry install
```

you may want to keep dev-requirements and pip-requirements updated too, by
```bash
poetry export --dev > dev-requirements && poetry export > pip-requirements
```

#### start server
```bash
poetry run python3 app/server.py
```

### II. run from docker-compose
```bash
docker-compose up --build
```

## 4. Configurations

#### Worker Config
Celery worker configuration and app's configuration files are in `app/config/configuration/configuration.py`

```python
class WorkerConfig:
    ...
```

contains all the configs related to the celery worker, for more celery configs, please refer to [general celery configs](https://docs.celeryproject.org/en/stable/userguide/configuration.html) and [SQS specific configs](https://docs.celeryproject.org/en/stable/getting-started/brokers/sqs.html#options)


#### All the rest
```python
class Config:
    ...
```
contains all the rest of configs including ratelimit, sentry, server port etc.

#### Queues mapping
The Queue-Task Mapping is defined in `app/config/queues.py`.
It uses a light weighted library https://github.com/ContextLogic/be-queue-python to enforce the naming convention and provided the convenience to setup the `celery_task_queues` and `celery_task_routes`.

e.g.
```python
QUEUES = Queues(
    [
        Queue(
            queue_name='python-backend-worker-template-add',
            task='app.tasks.tasks.add',
            ratelimit_name='python_backend_worker_template_add',
        ),
    ],
)
```

### Naming Convention
`queue_name` defines the short name of the SQS queue, the full name of the queue will be in the following pattern:
- {env}-{queue_name}
- if runs in local, {username}-{env}-{queue_name}

The DLQ of the queue will be in err-{queue_full_name}.

### Task Mapping
`task` defines the task name. 
Please follow the convention of 1:1 task queue mapping, i.e. only one type of task per queue.

### Ratelimiting(optional but highly recommended)
please see more defails below in the ratelimit integration section.

## 5. Integrations

### Sentry
To integrate with sentry, created a new sentry project, and put the DSN in the config

### Ratelimit
The worker provides a queue-level ratelimiting. It utilized [the new ratelimit service](https://alki.i.wish.com/) developed by Infra Platform Service Team.

- create a new domain for your project at https://alki.i.wish.com/domains?region=us-west-1. 
- create a new ratelimit corresponding to your queue in the domain created above.
- put ratelimit host and domain in the config
- put ratelimiter name in the queues.py

### Prometheus
The worker by default comes with these metircs:
1. `{prefix}_worker_tasks_count`, total count of tasks by name, queue and state, emitted by worker process when processing tasks.
2. `{prefix}_consumer_tasks_count`, total count of tasks by name, queue and state, emitted by consumer process when polling from queue.
3. `{prefix}_tasks_runtime_seconds`, task runtime (seconds), starting from prerun to postrun, emitted by worker process.
4. `{prefix}_tasks_latency_seconds`, task latency (seconds), starting from task received to task ready-to-run(prerun), emiited by worker process.

you can add additional metrics in app/metrics/metrics.py, please note that this application is a multi-process application, when defining new metrics, you should use multi process collector registry. For more details, please see https://github.com/prometheus/client_python#multiprocess-mode-gunicorn

### TD
You can defines 

# Work on producer side
Please see the example in examples/client

1. install required dependencies.
```bash
pip3 install -i https://pypi.infra.wish.com/simple be-queue
```

2. defines the Queue-Task Mapping, e.g.
```python
QUEUES = Queues(
    [
        Queue(
            queue_name='python-backend-worker-template-add',
            task='add',
        ),
        Queue(
            queue_name='python-backend-worker-template-count',
            task='retry_demo',
        )
    ],
)
QUEUES.build_celery(env='local')
```
make sure that the Queue-Task Mapping is the same as you defined in the BE worker.

3. create and init the celery app
```python
from celery import Celery
celery_app = Celery()
celery_app.config_from_object({
    'broker_transport_options': {
        'region': 'us-west-1',
    },
    'broker_url': 'sqs://',
    'task_queues': QUEUES.celery_task_queues(),
    'task_routes': QUEUES.celery_task_routes()
})
```

4. start sending tasks
```python
celery_app.send_task('retry_demo', args=(0,))
celery_app.send_task('add', args=(0,1))
```

# Develop your worker

### you can start working on the job processing logic at app/tasks/tasks.py

### 

# Code Layout
## app/ 
source code of the complete worker application

### app/config
configurations for worker, app, queues

### app/tasks
- base_task.py defines the retry policies for each task. More info in https://docs.celeryproject.org/en/stable/userguide/tasks.html#task-inheritance

- tasks.py defines each individual task function.

### app/utils/metrics
prometheus metrics.

### app/utils/sentry
sentry initialization

### app/utils/celery_signals
[celery signals](https://docs.celeryproject.org/en/stable/userguide/signals.html) handler functions to be executed when celery signal published,
they are mostly related to monitoring and observability (metrics and tracing).

### app/utils/transport
customized transport class with Queue-Level ratelimiting feature.

### app/utils/ratelimit
Ratelimit client

### app/utils/tracing
Jaeger and Opentracing

### app/utils/vault
Vault client

### app/utils/fluent
Fluent logger integrated with TD.

### app/server.py
main script to start both flask server and celery worker.

### examples/
various examples, including send tasks on producer side, sending logs to TD etc.

# FAQ
